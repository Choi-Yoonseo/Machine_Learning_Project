# Machine_Learning_Project [학번 : 2022131051, 이름 : 최윤서]

## Sentiment Analysis on Social Media Data : 트위터 데이터 기반 감성 분류 및 시각화

---

## 프로젝트 선정 이유  

최근에 SNS의 단점에 주목을 했었습니다. 왜냐하면, 인터넷 기술이 발전할수록 모든 기록은 인터넷상에 남게 되며 사람들은 각기 다른 감정을 표출하기 때문입니다. 이 감정들이 누군가를 칭찬하기 위해, 위로하기 위해 쓰이기도 하지만, 한 사람의 잘못에 너무 과몰입을 하여 비난을 하는 그런 집단행동들도 어느샌가 우리 사회에 스며든 것 같습니다. 그래서 SNS상에 사람들의 주어진 감정표현을 바탕으로 분석해보고 싶었습니다. 따라서 Sentiment140 데이터셋을 활용해 긍정(Positive) 또는 부정(Negative)의 감정을 분류하고, 시간에 따른 감성 변화와 주요 변화를 시각화하기 위해 감성 분석 모델의 구현을 시도해 보았습니다.

---

## Code Overview

1. 데이터 로드 및 전처리
2. 감성 변화 시각화 및 저장
3. 감성 변화 피크 탐지
4. 로지스틱 회귀 모델 학습 및 정확도 평가
   
---

## 코드 설명 (환경 : Colab)

### 필요한 라이브러리 import and install

<img width="711" alt="library" src="https://github.com/user-attachments/assets/baeda773-17ed-48d1-bed1-12916a086177" />

- 프로젝트에서 사용할 라이브러리의 기능과 역할을 설정 및 이후 모든 기반을 제공하는 부분.
- pandas : CSV파일 로드 및 데이터프레임 처리를 위한 라이브러리
- matplotlib : 그래프를 그리기 위한 라이브러리
- re : 특수문자 제거를 위한 라이브러리 (전처리이용)
- numpy : 수치 연산 및 배열을 위한 라이브러리
- scikit : 머신러닝 알고리즘과 데이터 처리 도구 제공
- tensorflow : 딥러닝을 위한 라이브러리

### **1. 데이터 로드 및 전처리**  
<img width="496" alt="text_preprocess" src="https://github.com/user-attachments/assets/eb30202a-dee6-4fd9-8e04-9f99eda6b252" />

- **데이터셋**: Sentiment140 (training.1600000.processed.noemoticon.csv)  
- **전처리 과정**:
   - 텍스트를 **소문자화**.
   - 특수 문자 및 불필요한 공백 제거.
   - 감성 레이블을 **긍정(4)** → POSITIVE, **부정(0)** → NEGATIVE로 변환.
   - 날짜 데이터를 파싱하여 시간 순서대로 정리.
     
<img width="842" alt="load_preprocess" src="https://github.com/user-attachments/assets/baa1286a-d553-4574-a22e-94d3387c96fc" />
   
   - 데이터 로드
    CSV 파일에서 데이터를 읽음.
    date, text, target 열만 선택하여 불필요한 데이터를 제거.

   - 텍스트 데이터 전처리
    text_preprocessing 함수로 텍스트를 소문자로 변환, 특수문자 제거, 공백 정리.

   - 감성 레이블 변환
    target 열의 레이블을 0 → negative, 4 → positive로 변환

   - 결측값 및 날짜 처리
    결측값을 제거하고, date 열을 날짜 형식으로 변환.
    날짜 변환 실패 행을 삭제하여 데이터 품질을 유지.

   - 전처리된 데이터 반환
    최종적으로 정리된 데이터를 반환하며, 이후 분석과 모델 학습에 사용.
     
### **2. 감성 변화 시각화**  
<img width="764" alt="sentiment trends" src="https://github.com/user-attachments/assets/bae8f965-b22a-4d27-8db5-ad2c9747b019" />


- 감성 변화 시각화 및 저장 함수
- 
  **데이터 처리 및 집계**
  - 날짜 정보만을 추출하고, 긍정과 부정별로 행렬 형식으로 변환하며 결측값은 0으로 채움
  - 그래프의 크기를 figsize-(12,6)으로 설정하여 그래프를 생성
  - X-axis Label : Date , Y-axis Label : Number of Tweets
  

### 3. 변화 피크 탐지 (peak_detection)
<img width="766" alt="peak detection" src="https://github.com/user-attachments/assets/cef70f71-ebd5-40da-a54f-f6f8a8e5f7fb" />

- 날짜를 표준 형식으로 변환하고 target별 트윗 수를 날짜별로 집계하고, 변환에 실패한 비정상 데이터는 제거처리.
- 날짜별 변화량의 차이를 계산값을 바탕으로 변화량이 큰 날짜를 탐지(detect).
- 피크인 날짜를 강조하여 표시하고 Peak를 강조하기 위해 피크 날짜에 빨간선(axvline)을 추가하여 표시




### **4. 모델 학습 및 평가 (정확도 평가 함수)**  
accuracy_evaluation 함수는 로지스틱 회귀(logistic regression)을 사용하여 학습 및 테스트 진행 및 정확도와 혼동행렬 출력.
- **TF-IDF(Term Frequency-Inverse Document Frequency)벡터화**
  - 텍스트 데이터를 수치 벡터로 변환하여 머신러닝에 적합하게 변환
  - max_features=5000설정으로 최대 5000개의 중요한 단어를 선택하여 벡터 변환
  - negative,positive를 각각 0,1로 변환하여 머신러닝 학습에 적합성을 높임
 
- **Data Distribution**
  - 학습 데이터와 테스트 데이터를 분리하여 모델의 학습 성능과 일반화 성능을 독립적으로 평가하기 위함
  - specific = 80%(train_set) , 20%(test_set)
    
- **Logistic Regression 모델**:
   - 시그모이드 함수 사용 :P(y=1|x) = 1 / (1 + e^(-(mx + b))) -> 출력값이 항상 [0,1] 범위 내에 있도록 보장
   - Logistic Regression은 이진 분류 문제를 해결하기 위해 설계된 모델이므로 즉 긍정과 부정으로 분류하는 감성분석에서는
     Logistic Regression이 더 적합함.
   - Logistic REgression은 계산적으로 유리하며, 대규모 데이터셋에서도 빠른 학습이 가능하다는 효율성을 지님
   - 확률 해석 가능성 즉, 출력값이 [0,1] 범위의 확률로 해석이 가능하기 때문에 이 모델이 더 적합

     **왜 Linear Regression이 아닌가?**
        - 선형 회귀는 연속형 출력 값을 예측하는데 사용.
        - 이진 분류에 해당하는 감성 분석에는 선형방정식의 계산은 옳지 않음
        - 시그모이드 함수를 사용하는 Logistic Regression은 비선형관계처리에 더욱 유용
     
 - **혼동행렬(Confusion_matrix)가 무엇인가?**
   - 혼동행렬은 Logistic Regression과 같은 분류 모델의 성능을 평가하기 위한 도구이며, Logistic Regression과는 독립적인 평가 방법
   - 분류 모델이 실제값과 예측값 간의 관계를 2차원 표 형태로 요약한 것. Logistic Regressionr과 같이 이진 분류 문제나 다중 클래스 분류 문제에서 모델의 성능을 평가하는데 사용
  
  
---

   ### **혼동 행렬의 구조**

| 실제\예측       | 예측 부정 (0)  | 예측 긍정 (1)  |
|-----------------|----------------|----------------|
| **실제 부정 (0)** | True Negative (TN) | False Positive (FP) |
| **실제 긍정 (1)** | False Negative (FN) | True Positive (TP) |

- **True Positive (TP)**: 긍정으로 올바르게 예측된 경우.
- **True Negative (TN)**: 부정으로 올바르게 예측된 경우.
- **False Positive (FP)**: 부정을 긍정으로 잘못 예측한 경우.
- **False Negative (FN)**: 긍정을 부정으로 잘못 예측한 경우.

---

   ### **혼동 행렬의 목적**

1. **정확도 평가**
   - 모델이 얼마나 정확히 데이터를 분류했는지 파악.

2. **성능 분석**
   - 잘못된 예측(FP, FN)이 많은 특정 클래스나 데이터 유형을 확인하여 모델의 개선 방향을 모색.

3. **평가지표 계산**
   - 정밀도(Precision), 재현율(Recall), F1-점수(F1-Score)와 같은 주요 성능 지표를 혼동 행렬을 기반으로 계산.

---

### **혼동 행렬의 원리**

1. **비교**
   - 실제 데이터 레이블(예: 0, 1)과 모델 예측 값을 비교.
2. **집계**
   - 각 조합의 발생 횟수를 집계하여 TN, TP, FP, FN 값을 계산.
3. **행렬 표현**
   - 집계 결과를 2x2 표로 반환.

---

### **혼동 행렬을 활용한 지표 계산**

혼동 행렬의 사용

- **정밀도(Precision)**: 예측된 긍정 중 실제로 긍정인 비율  
  Precision = TP / (TP + FP)

- **재현율(Recall)**: 실제 긍정 중 올바르게 예측된 비율  
  Recall = TP / (TP + FN)
  
- **F1-점수(F1-Score)**: 정밀도와 재현율의 조화 평균  
  F1-Score = 2 * (Precision * Recall) / (Precision + Recall)
          
### **4. 주요 코드 구조**  
- text_preprocessing(): 텍스트 전처리 함수.  
- load_preprocess(): 데이터셋 로드 및 전처리.  
- sentiment_trends(): 감성 변화 시각화 및 저장.  
- peak_detection(): 감성 변화 피크 탐지.  
- accuaracy_evaluation: Logistic Regression 모델 정확도 평가.  

---

## 실행 결과  

### **감성 추이 시각화**  
시간에 따른 긍정 및 부정 트윗 수를 시각화한 결과
  
<img width="1086" alt="스크린샷 2024-12-18 오후 9 45 36" src="https://github.com/user-attachments/assets/ad592371-9378-41ee-855c-2ba8a9867060" />


---

### **감성 변화 피크 탐지**  
감성 변화가 급격한 날짜를 강조하여 표시한 결과:  

<img width="1080" alt="스크린샷 2024-12-18 오후 9 45 42" src="https://github.com/user-attachments/assets/702b7753-3b3b-4d35-9b07-1f05d8692c2a" />


---

### **모델 성능 평가**  

## 모델 성능 평가

Logistic Regression을 사용하여 모델 성능을 평가

---

### 1. 정확도
- **정확도(Accuracy)**: **79.04%**

---

### 2. 혼동 행렬
혼동 행렬을 통한 모델의 분류 성능을 시각적으로 제시

| 실제\예측       | 부정 (0)      | 긍정 (1)      |
|-----------------|---------------|---------------|
| **부정 (0)**    | 123,842       | 35,652        |
| **긍정 (1)**    | 31,417        | 129,089       |

- **True Negatives (TN)**: 123,842 (부정을 올바르게 예측한 수)
- **True Positives (TP)**: 129,089 (긍정을 올바르게 예측한 수)
- **False Positives (FP)**: 35,652 (긍정으로 잘못 예측된 부정)
- **False Negatives (FN)**: 31,417 (부정으로 잘못 예측된 긍정)

---

### 3. 분류 보고서

| 지표             | 부정 (0)      | 긍정 (1)      | 가중 평균(Weighted Avg) |
|------------------|---------------|---------------|--------------------------|
| **정밀도(Precision)** | 80%          | 78%          | 79%                      |
| **재현율(Recall)**    | 78%          | 80%          | 79%                      |
| **F1-점수(F1-Score)** | 79%          | 79%          | 79%                      |

---

### 4. 주요 결과
- **정밀도(Precision)**: 예측된 긍정/부정 중 실제로 올바르게 분류된 비율.
- **재현율(Recall)**: 실제 긍정/부정 데이터 중 정확히 예측된 비율.
- **F1-점수(F1-Score)**: 정밀도와 재현율의 균형을 나타내는 지표.

Logistic Regression 모델은 테스트 데이터에서 균형 잡힌 성능을 보여주었고, 약 79%의 정확도를 달성


### 5. 정확도를 높이기 위한 시도

- 어근 추출을 통한 정확한 감정 단어 파악 시도로 정확도를 올리려고 시도해보았습니다.
  
## 개선된 추가 코드

<img width="793" alt="스크린샷 2024-12-19 오후 1 38 35" src="https://github.com/user-attachments/assets/682cc3f6-3826-4e0b-ad0f-d91d107380da" />


  ## **주요 학습 내용**
1. **전처리의 영향**:
   - 텍스트 전처리는 모델 성능에 중요한 역할을 담당.
   - 하지만 이번 시도에서는 고급 전처리(예: 불용어 제거, 어근 추출)로 인해 **정확도가 하락**하는 결과도출 (79.00% → 77.20%).
  

2. **데이터의 특성**:
   - 데이터셋 자체가 노이즈 또는 편향을 포함할 가능성이 있으며, 이는 전체적인 모델 성능에 영향을 미친것으로 보임.
   - 특히, 전처리 과정 중 불용어 제거 과정에서 "not" 또는 "very"와 같은 중요한 감성 단어가 삭제되어 정확도가 낮아진 것으로 추측
   - colab상에서 실행시 런타임이 기존의 코드보다는 커져서 실행에 불편함이 동반됨
  

3. ## 정확도 도식화
   ## **결과 비교**
| 전처리 방법            | 정확도  | 정밀도 (클래스 0) | 재현율 (클래스 0) | 정밀도 (클래스 1) | 재현율 (클래스 1) |
|-----------------------|--------|------------------|------------------|------------------|------------------|
| **기본 전처리**        | 79.00% | 80%              | 78%              | 78%              | 80%              |
| **고급 전처리**        | 77.20% | 78%              | 75%              | 76%              | 79%              |


## 프로젝트 의의
---

## **1. 데이터 중심적 사고의 중요성**
- **Sentiment140** 데이터셋과 같은 대규모 텍스트 데이터를 다룸으로써, 데이터 전처리와 품질 관리가 모델 성능에 미치는 영향을 깊이 이해할 수 있었습니다.
- 이미 알려진 데이터를 분석하고 전처리 방식을 설계하며, 그 결과가 그래프에 어떻게 표현되는지, 정확도가 어느정도의 수치로 나타나는지 확인했습니다.

---

## **2. 기초 모델의 활용 가능성**
- **로지스틱 회귀(Logistic Regression)**와 같은 기초 모델을 활용하여 텍스트 분류 작업에서도 높은 성능(79.04%)을 달성할 수 있음을 확인했습니다.
- 특히 기계학습과응용 및 타과의 과목(기초인공지능)을 수강하면서 linear regression에 대한 지식이 있는 정도 였는데 이 프로젝트를 진행하면서 모델에 따라 회귀모델이 달라짐을 깨달았고
  위에 서술한 바와 같이 모델의 목적성에 따라 회귀모델을 적절하게 선택해야 함을 깨달았습니다.

---

## **3. 전처리 기법의 영향**
- 정확도를 높이려는 시도를 하기 위해 어떤 방식지 적합한지를 고민해보았습니다. 감정분류가 적절하게 되지 않았다면 정확도가 떨어졌을 것이라는 판단하에 추가적으로 코드를 작성하여 진행해보았습니다.
- 하지만 **불용어 제거 및 어근 추출**과 같은 고급 전처리 기법이 항상 긍정적인 결과를 가져오지 않는다는 점을 발견했습니다.
- 이는 전처리 과정이 무조건 정확도의 상승에 영향을 미친다는 것을 시사한다기 보다는, 단어를 더 제거하는 과정에서 원래 감정표현이라고 인식되었던 단어들도 같이 삭제되었을 것이라고 에측할 수 있었습니다.
- 이번 프로젝트에서의 고급 전처리는 부정어("not")와 같은 중요한 정보를 손실시킴으로 인하여 모델의 성능 저하 및 정확도(Accuracy)저하로 이어졌습니다.
- 모델을 구현하는 코드가 복잡하고 섬세할수록 정확도가 향상될 줄 알았지만 꼭 그렇지 않다는 점을 깨달았고 이 점이 이번 프로젝트를 진행하면서 매우 흥미로운 부분중 하나였습니다.

---

## **4. 향후 확장 가능성**
- 이번 프로젝트는 간단한 기초 모델을 기반으로 진행되었지만, 조사 결과 LSTM, GRU 또는 **BERT**와 같은 고급 딥러닝 모델을 사용하면 더 나은 정확도를 달성할 확률이 높다는 것을 깨달았습니다.
- 하지만 현실적으로 하나의 컴퓨터로 진행하다보니 런타임 문제 및 실행과정에서 문제가 발생했습니다. 기회가 된다면 이런 고급 딥러닝 모델들을 추가적으로 배워 모델의 성능을 향상시켜보고 싶다는 의지를 갖게 되었습니다.

---
## Colab 주소
https://colab.research.google.com/drive/1pHOcQB9qBuVz3D4HYfvgiSQwvy4NqHmh?usp=sharing


